{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search & AI/RAG Pipelines\n",
    "\n",
    "This notebook demonstrates how to combine **full-text search** with **vector similarity search** to build a document search engine suitable for RAG (Retrieval-Augmented Generation) pipelines.\n",
    "\n",
    "SurrealDB supports both BM25-based full-text search and HNSW vector indexes natively, making it a strong choice for AI applications that need hybrid retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- SurrealDB running locally (`docker run --rm -p 8000:8000 surrealdb/surrealdb:latest start --user root --pass root`)\n",
    "- Project dependencies installed (`uv sync`)\n",
    "- A `.env` file in the project root (optional, falls back to defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup: add project root to path and configure SurrealDB connection\nimport os, sys\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\nsys.path.append(project_root)\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom src.surreal_orm import SurrealDBConnectionManager\n\nSurrealDBConnectionManager.set_connection(\n    os.getenv(\"SURREALDB_URL\", \"ws://localhost:8000\"),\n    os.getenv(\"SURREALDB_USER\", \"root\"),\n    os.getenv(\"SURREALDB_PASS\", \"root\"),\n    os.getenv(\"SURREALDB_NAMESPACE\", \"ns\"),\n    os.getenv(\"SURREALDB_DATABASE\", \"db\"),\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Full-Text Search (BM25)\n",
    "\n",
    "Full-text search is ideal when your users type natural language queries against text content. SurrealDB uses BM25 scoring under the hood, which ranks documents by term frequency and inverse document frequency.\n",
    "\n",
    "**When to use FTS:**\n",
    "- Keyword-based search (e.g., \"quantum physics\")\n",
    "- When exact term matching matters\n",
    "- When you need highlighted snippets in results\n",
    "\n",
    "> **Note:** Full-text search requires a `DEFINE INDEX ... SEARCH ANALYZER` on the SurrealDB side. The ORM generates the queries, but the index must exist for `@N@` match operators to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define a model for articles with text fields we'll search against\nfrom src.surreal_orm import BaseSurrealModel, SurrealConfigDict, SearchScore, SearchHighlight\n\nclass Article(BaseSurrealModel):\n    model_config = SurrealConfigDict(table_name=\"article\")\n\n    id: str | None = None\n    title: str\n    body: str = \"\"\n    category: str = \"general\""
  },
  {
   "cell_type": "code",
   "id": "g2guxaxwvp9",
   "source": "# Define a text analyzer and FTS indexes on the SurrealDB side\n# These are required for the @N@ match operators used by .search()\nawait Article.raw_query(\"\"\"\n    DEFINE ANALYZER IF NOT EXISTS simple_analyzer TOKENIZERS blank, class FILTERS lowercase;\n    DEFINE INDEX IF NOT EXISTS ft_title ON article FIELDS title\n        SEARCH ANALYZER simple_analyzer BM25(1.2, 0.75) HIGHLIGHTS;\n    DEFINE INDEX IF NOT EXISTS ft_body ON article FIELDS body\n        SEARCH ANALYZER simple_analyzer BM25(1.2, 0.75) HIGHLIGHTS;\n\"\"\")\nprint(\"FTS analyzer and indexes defined on 'article' table\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample articles for searching\n",
    "articles = [\n",
    "    Article(title=\"Introduction to Quantum Computing\", body=\"Quantum computers use qubits to perform computations.\", category=\"science\"),\n",
    "    Article(title=\"Quantum Physics Explained\", body=\"Quantum physics studies the behaviour of matter at atomic scales.\", category=\"science\"),\n",
    "    Article(title=\"Classical Computing Architecture\", body=\"Von Neumann architecture is the foundation of classical computers.\", category=\"technology\"),\n",
    "    Article(title=\"Machine Learning Basics\", body=\"Machine learning algorithms learn patterns from data.\", category=\"technology\"),\n",
    "    Article(title=\"Deep Learning and Neural Networks\", body=\"Neural networks with many layers can learn complex representations.\", category=\"technology\"),\n",
    "]\n",
    "\n",
    "for article in articles:\n",
    "    await article.save()\n",
    "    print(f\"Saved: {article.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic full-text search on the title field\n",
    "# This generates: SELECT * FROM articles WHERE title @0@ 'quantum'\n",
    "results = await Article.objects().search(title=\"quantum\").exec()\n",
    "print(f\"Found {len(results)} articles matching 'quantum':\")\n",
    "for r in results:\n",
    "    print(f\"  - {r.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-text search with BM25 relevance scoring and highlighted snippets\n",
    "# SearchScore(0) references the @0@ match operator in the query\n",
    "results = await Article.objects().search(title=\"quantum\").annotate(\n",
    "    relevance=SearchScore(0),\n",
    "    snippet=SearchHighlight(\"<b>\", \"</b>\", 0),\n",
    ").exec()\n",
    "\n",
    "print(\"Search results with relevance scores:\")\n",
    "for r in results:\n",
    "    # The annotated fields are attached to each result instance\n",
    "    relevance = getattr(r, \"relevance\", \"N/A\")\n",
    "    snippet = getattr(r, \"snippet\", \"N/A\")\n",
    "    print(f\"  [{relevance}] {r.title}\")\n",
    "    print(f\"     Snippet: {snippet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-field search: search across title AND body simultaneously\n",
    "# Each field gets its own match reference (@0@, @1@, etc.)\n",
    "results = await Article.objects().search(title=\"learning\", body=\"neural\").annotate(\n",
    "    title_score=SearchScore(0),\n",
    "    body_score=SearchScore(1),\n",
    ").exec()\n",
    "\n",
    "print(\"Multi-field search results:\")\n",
    "for r in results:\n",
    "    ts = getattr(r, \"title_score\", \"N/A\")\n",
    "    bs = getattr(r, \"body_score\", \"N/A\")\n",
    "    print(f\"  {r.title} (title: {ts}, body: {bs})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y0obe9sm3q",
   "source": "## 2. Vector Similarity Search (KNN with HNSW)\n\nVector search finds documents by semantic similarity rather than keyword matching.\nYou store embedding vectors alongside your data, then query for the K nearest\nneighbours using SurrealDB's HNSW index.\n\n**When to use vector search:**\n- Semantic search (\"find similar documents\")\n- RAG pipelines (retrieve relevant context for LLMs)\n- Recommendation systems\n\n> **Note:** Vector search requires a `DEFINE INDEX ... HNSW` on the field. The ORM generates `<|K|>` KNN queries, but the index must exist.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Define a model with a vector field for embeddings\n# VectorField[4] means 4-dimensional vectors (tiny for demo; real apps use 768-1536)\nfrom src.surreal_orm.fields import VectorField\n\nclass Document(BaseSurrealModel):\n    model_config = SurrealConfigDict(table_name=\"document\")\n\n    id: str | None = None\n    title: str\n    content: str = \"\"\n    embedding: VectorField[4]  # Small dimension for demo"
  },
  {
   "cell_type": "code",
   "id": "beofaxvfbv",
   "source": "# Define HNSW vector index and FTS index for hybrid search\n# HNSW index is required for the <|N|> KNN operator used by .similar_to()\nawait Document.raw_query(\"\"\"\n    DEFINE INDEX IF NOT EXISTS vec_idx ON document FIELDS embedding\n        HNSW DIMENSION 4 DIST COSINE TYPE F32;\n    DEFINE INDEX IF NOT EXISTS ft_content ON document FIELDS content\n        SEARCH ANALYZER simple_analyzer BM25(1.2, 0.75) HIGHLIGHTS;\n\"\"\")\nprint(\"HNSW and FTS indexes defined on 'document' table\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents with mock embeddings\n",
    "# In production, you'd compute these with an embedding model (e.g., OpenAI ada-002)\n",
    "docs = [\n",
    "    Document(title=\"Python Basics\", content=\"Learn Python programming\", embedding=[0.1, 0.9, 0.2, 0.3]),\n",
    "    Document(title=\"JavaScript Guide\", content=\"Frontend development with JS\", embedding=[0.2, 0.8, 0.3, 0.4]),\n",
    "    Document(title=\"Rust Systems\", content=\"Systems programming in Rust\", embedding=[0.8, 0.1, 0.9, 0.7]),\n",
    "    Document(title=\"Go Concurrency\", content=\"Concurrent programming with Go\", embedding=[0.7, 0.2, 0.8, 0.6]),\n",
    "    Document(title=\"SQL Databases\", content=\"Relational database design\", embedding=[0.4, 0.5, 0.4, 0.5]),\n",
    "]\n",
    "\n",
    "for doc in docs:\n",
    "    await doc.save()\n",
    "    print(f\"Saved: {doc.title} with embedding {doc.embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN similarity search: find the 3 most similar documents to a query vector\n",
    "# This generates: SELECT *, vector::distance::knn() AS _knn_distance\n",
    "#                  FROM documents WHERE embedding <|3|> $vec\n",
    "#                  ORDER BY _knn_distance\n",
    "query_vector = [0.15, 0.85, 0.25, 0.35]  # Similar to Python/JS docs\n",
    "\n",
    "results = await Document.objects().similar_to(\"embedding\", query_vector, limit=3).exec()\n",
    "print(\"Top 3 similar documents:\")\n",
    "for doc in results:\n",
    "    distance = getattr(doc, \"_knn_distance\", \"N/A\")\n",
    "    print(f\"  - {doc.title} (distance: {distance})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector search with search effort tuning (ef parameter)\n",
    "# Higher ef = more accurate but slower; useful for large datasets\n",
    "results = await Document.objects().similar_to(\n",
    "    \"embedding\", query_vector, limit=3, ef=40\n",
    ").exec()\n",
    "print(\"Results with ef=40 (higher accuracy):\")\n",
    "for doc in results:\n",
    "    print(f\"  - {doc.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine vector search with traditional filters\n",
    "# Useful for scoped retrieval (e.g., only search within a category)\n",
    "systems_vector = [0.75, 0.15, 0.85, 0.65]  # Similar to Rust/Go docs\n",
    "results = await Document.objects().filter(\n",
    "    title__contains=\"Go\"\n",
    ").similar_to(\"embedding\", systems_vector, limit=5).exec()\n",
    "\n",
    "print(\"Filtered vector search (title contains 'Go'):\")\n",
    "for doc in results:\n",
    "    print(f\"  - {doc.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hybrid Search (Vector + FTS)\n",
    "\n",
    "Hybrid search combines the best of both worlds: semantic understanding from vectors and exact keyword matching from FTS. Results are merged using **Reciprocal Rank Fusion (RRF)**, which balances the rankings from both retrieval methods.\n",
    "\n",
    "**When to use hybrid search:**\n",
    "- RAG pipelines where both meaning and keywords matter\n",
    "- Search engines where users expect both exact and fuzzy matches\n",
    "- When neither pure FTS nor pure vector gives good enough recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cleanup: remove all test data and indexes\nawait Article.raw_query(\"REMOVE TABLE IF EXISTS article\")\nawait Document.raw_query(\"REMOVE TABLE IF EXISTS document\")\nawait Article.raw_query(\"REMOVE ANALYZER IF EXISTS simple_analyzer\")\nprint(\"Cleanup complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Notes\n",
    "\n",
    "- **Embedding dimensions:** Use real embedding models in production. OpenAI `text-embedding-ada-002` produces 1536-dimensional vectors. Cohere and open-source models vary (384-4096).\n",
    "- **Index configuration:** For large datasets, tune HNSW parameters (`m`, `efc`) in your migration's `CreateIndex` operation.\n",
    "- **Vector types:** Use `VectorField[1536, \"F32\"]` for single-precision or `VectorField[1536, \"F64\"]` for double-precision.\n",
    "- **FTS analyzers:** Define custom analyzers with tokenizers and filters (e.g., stemming, stop words) using `DefineAnalyzer` in migrations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}